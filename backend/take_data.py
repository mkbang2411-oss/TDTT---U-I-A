from serpapi import GoogleSearch
import pandas as pd
import os
import time

# ‚öôÔ∏è C·∫•u h√¨nh
SERP_API_KEY = "965493118ea3afd38375442b8a2345f83ad60b1a6deea265d96ed02a81d47c94"  # Nh·ªõ ƒëi·ªÅn key th·∫≠t c·ªßa b·∫°n
CSV_FILE = "Data.csv"


def get_places(query: str, lat: float, lon: float):
    """G·ªçi SerpAPI ƒë·ªÉ l·∫•y danh s√°ch qu√°n g·∫ßn v·ªã tr√≠ ch·ªâ ƒë·ªãnh."""
    if not SERP_API_KEY:
        print("‚ö†Ô∏è Ch∆∞a c√≥ SERP_API_KEY. H√£y ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c s·ª≠a trong code.")
        return []

    params = {
        "engine": "google_maps",
        "q": query,
        "ll": f"@{lat},{lon},15z",
        "type": "search",
        "hl": "vi",
        "api_key": SERP_API_KEY
    }

    search = GoogleSearch(params)
    results = search.get_dict()
    return results.get("local_results", [])


def parse_place_data(places: list):
    """Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu t·ª´ SerpAPI th√†nh DataFrame"""
    if not places:
        return pd.DataFrame()

    records = []
    for p in places:
        if "gps_coordinates" not in p:
            continue

        # ‚ùå Kh√¥ng c·∫ßn l·∫•y h√¨nh ·∫£nh n·ªØa
        image_url = ""

        # üçú Th·ª±c ƒë∆°n
        menu_items = ""
        if "menu_items" in p and isinstance(p["menu_items"], list):
            menu_items = ", ".join([i.get("title", "") for i in p["menu_items"]])

        # üí∞ Gi√°
        price = p.get("price", p.get("price_level", ""))

        # üïí Gi·ªù m·ªü c·ª≠a
        gio_mo_cua = p.get("hours", "")
        if not gio_mo_cua or str(gio_mo_cua).strip() == "":
            gio_mo_cua = "ƒêang m·ªü c·ª≠a ‚ãÖ ƒê√≥ng c·ª≠a l√∫c 22:00"

        records.append({
            "data_id": p.get("data_id", ""),
            "ten_quan": p.get("title", ""),
            "dia_chi": p.get("address", ""),
            "so_dien_thoai": p.get("phone", ""),
            "rating": p.get("rating", ""),
            "gio_mo_cua": gio_mo_cua,
            "gia_trung_binh": price,
            "thuc_don": menu_items,
            "hinh_anh": image_url,
            "lat": p["gps_coordinates"]["latitude"],
            "lon": p["gps_coordinates"]["longitude"]
        })

    return pd.DataFrame(records)


def save_places_to_csv(df_new: pd.DataFrame, CSV_FILE: str = CSV_FILE):
    """L∆∞u DataFrame v√†o CSV, tr√°nh tr√πng l·∫∑p"""
    if df_new.empty:
        print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi.")
        return

    folder = os.path.dirname(CSV_FILE)
    if folder:
        os.makedirs(folder, exist_ok=True)

    if not os.path.exists(CSV_FILE) or os.stat(CSV_FILE).st_size == 0:
        df_new.to_csv(CSV_FILE, index=False)
        print(f"üíæ T·∫°o m·ªõi {CSV_FILE} ({len(df_new)} d√≤ng).")
        return

    try:
        df_old = pd.read_csv(CSV_FILE)
    except Exception:
        df_old = pd.DataFrame()

    df_all = pd.concat([df_old, df_new], ignore_index=True)
    df_all.drop_duplicates(subset=["ten_quan", "dia_chi"], inplace=True)
    df_all.to_csv(CSV_FILE, index=False)
    print(f"‚úÖ C·∫≠p nh·∫≠t {CSV_FILE}: t·ªïng {len(df_all)} qu√°n.")


def crawl_and_save_places(query: str, lat: float, lon: float):
    """Crawl d·ªØ li·ªáu + parse + l∆∞u CSV"""
    print(f"üöÄ Crawling '{query}' t·∫°i ({lat}, {lon}) ...")
    places = get_places(query, lat, lon)
    df_new = parse_place_data(places)
    if not df_new.empty:
        save_places_to_csv(df_new, CSV_FILE)
    else:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu thu ƒë∆∞·ª£c.")
    return df_new.to_dict(orient="records")


# ‚úÖ Cho ph√©p ch·∫°y th·ªß c√¥ng ƒë·ªÉ test CLI
if __name__ == "__main__":
    DISTRICTS = {
        "B√¨nh Th·∫°nh": (10.8050, 106.6960),
        "Ph√∫ Nhu·∫≠n": (10.7990, 106.6800),
        "T√¢n B√¨nh": (10.8010, 106.6520),
        "G√≤ V·∫•p": (10.8340, 106.6800),
        "Qu·∫≠n 10": (10.7735, 106.6670),
        "Th·ªß ƒê·ª©c": (10.8490, 106.7600)
    }

    query = input("üîç Nh·∫≠p t·ª´ kh√≥a mu·ªën t√¨m (vd: ph·ªü, tr√† s·ªØa, c∆°m t·∫•m): ").strip()
    print(f"üöÄ B·∫Øt ƒë·∫ßu crawl '{query}' ...\n")

    for name, (lat, lon) in DISTRICTS.items():
        print(f"üìç {name} ({lat}, {lon})")
        data = crawl_and_save_places(query, lat, lon)
        print(f"‚úÖ {name}: {len(data)} k·∫øt qu·∫£.\n")
        time.sleep(5)

    print("üéâ Ho√†n t·∫•t! D·ªØ li·ªáu l∆∞u trong Data.csv")
