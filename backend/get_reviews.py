import pandas as pd
import requests
import json
import os
import time

# âš™ï¸ Cáº¥u hÃ¬nh
SERP_API_KEY = "919519991034d358c7da2ae6f11bc21ded6a8e50a6193c568000e4ef8c9d8e2a"  # nháº­p key cá»§a báº¡n
CSV_FILE = "Data.csv"
REVIEWS_FILE = "reviews.json"


def get_google_reviews(data_id, max_reviews=16):
    """
    Gá»i SerpAPI Ä‘á»ƒ láº¥y tá»‘i Ä‘a `max_reviews` review (tá»‘i Ä‘a 20)
    KhÃ´ng yÃªu cáº§u pháº£i cÃ³ Ä‘á»§ cÃ¡c má»©c sao.
    """
    if not SERP_API_KEY:
        print("âš ï¸ ChÆ°a cÃ³ SERP_API_KEY. HÃ£y Ä‘áº·t biáº¿n mÃ´i trÆ°á»ng hoáº·c sá»­a trong code.")
        return []

    all_reviews = []
    page_token = None
    page = 1

    while len(all_reviews) < max_reviews:
        params = {
            "engine": "google_maps_reviews",
            "data_id": data_id,
            "api_key": SERP_API_KEY,
        }
        if page_token:
            params["next_page_token"] = page_token

        try:
            res = requests.get("https://serpapi.com/search.json", params=params, timeout=30)
            if res.status_code != 200:
                print(f"âš ï¸ Lá»—i HTTP {res.status_code} (page {page}) cho data_id={data_id}")
                break

            data = res.json()
            reviews = data.get("reviews", [])
            if not reviews:
                break

            for r in reviews:
                all_reviews.append({
                    "user": r.get("user", {}).get("name", "áº¨n danh"),
                    "avatar": r.get("user", {}).get("thumbnail", ""),
                    "rating": r.get("rating", ""),
                    "comment": r.get("snippet", ""),
                    "date": r.get("date", "")
                })
                if len(all_reviews) >= max_reviews:
                    break

            page_token = data.get("serpapi_pagination", {}).get("next_page_token")
            if not page_token:
                break

            page += 1
            time.sleep(3)

        except Exception as e:
            print(f"âŒ Lá»—i khi gá»i API cho {data_id}: {e}")
            break

    return all_reviews[:max_reviews]


def crawl_all_reviews():
    """
    Láº¥y review cho toÃ n bá»™ quÃ¡n trong Data.csv
    vÃ  lÆ°u vÃ o reviews.json
    """
    if not os.path.exists(CSV_FILE):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {CSV_FILE}")
        return

    df = pd.read_csv(CSV_FILE)
    all_reviews = {}

    if os.path.exists(REVIEWS_FILE):
        with open(REVIEWS_FILE, "r", encoding="utf-8") as f:
            try:
                all_reviews = json.load(f)
            except json.JSONDecodeError:
                all_reviews = {}

    print(f"ğŸ“Š Tá»•ng quÃ¡n trong {CSV_FILE}: {len(df)}")
    print("ğŸš€ Báº¯t Ä‘áº§u láº¥y review...")

    for idx, row in df.iterrows():
        data_id = str(row.get("data_id", "")).strip()
        ten_quan = row.get("ten_quan", "KhÃ´ng tÃªn")

        if not data_id:
            continue

        # âœ… Náº¿u Ä‘Ã£ cÃ³ >= 16 review thÃ¬ bá» qua
        existing = all_reviews.get(data_id, [])
        if len(existing) >= 16:
            print(f"âœ… Bá» qua {ten_quan} (Ä‘Ã£ cÃ³ {len(existing)} review)")
            continue

        print(f"ğŸ” Äang láº¥y review cho {ten_quan}...")
        reviews = get_google_reviews(data_id, max_reviews=20)
        all_reviews[data_id] = reviews

        print(f"âœ… {idx+1}/{len(df)} - {ten_quan}: {len(reviews)} review")

        # LÆ°u dáº§n Ä‘á»ƒ trÃ¡nh máº¥t dá»¯ liá»‡u
        with open(REVIEWS_FILE, "w", encoding="utf-8") as f:
            json.dump(all_reviews, f, ensure_ascii=False, indent=2)

        time.sleep(5)  # trÃ¡nh vÆ°á»£t giá»›i háº¡n API

    print(f"ğŸ‰ HoÃ n táº¥t! Dá»¯ liá»‡u lÆ°u vÃ o {REVIEWS_FILE}")


if __name__ == "__main__":
    crawl_all_reviews()
