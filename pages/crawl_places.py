from serpapi import GoogleSearch
import pandas as pd
import os
import time

# ğŸ”‘ Thay báº±ng key SerpAPI tháº­t cá»§a báº¡n
SERP_API_KEY = ""
CSV_FILE = "Data.csv"


def get_places(query, lat, lon):
    """Gá»i SerpAPI Ä‘á»ƒ láº¥y danh sÃ¡ch quÃ¡n gáº§n vá»‹ trÃ­ chá»‰ Ä‘á»‹nh"""
    params = {
        "engine": "google_maps",
        "q": query,
        "ll": f"@{lat},{lon},15z",
        "type": "search",
        "hl": "vi",
        "api_key": SERP_API_KEY
    }
    search = GoogleSearch(params)
    results = search.get_dict()
    return results.get("local_results", [])


def save_places_to_csv(places, CSV_FILE="Data.csv"):
    """LÆ°u danh sÃ¡ch quÃ¡n vÃ o CSV, trÃ¡nh trÃ¹ng láº·p vÃ  lá»—i file trá»‘ng"""
    if not places:
        print("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u má»›i Ä‘á»ƒ lÆ°u.")
        return pd.DataFrame()

    new_data = []
    for p in places:
        if "gps_coordinates" not in p:
            continue
        new_data.append({
            "ten_quan": p.get("title", ""),
            "dia_chi": p.get("address", ""),
            "so_dien_thoai": p.get("phone", ""),
            "rating": p.get("rating", ""),
            "gio_mo_cua": p.get("hours", ""),
            "lat": p["gps_coordinates"]["latitude"],
            "lon": p["gps_coordinates"]["longitude"]
        })

    df_new = pd.DataFrame(new_data)

    # ğŸ§© Táº¡o thÆ° má»¥c náº¿u cáº§n
    folder = os.path.dirname(CSV_FILE)
    if folder:
        os.makedirs(folder, exist_ok=True)

    # ğŸ§© Náº¿u file chÆ°a tá»“n táº¡i hoáº·c trá»‘ng -> táº¡o má»›i
    if not os.path.exists(CSV_FILE) or os.stat(CSV_FILE).st_size == 0:
        df_new.to_csv(CSV_FILE, index=False)
        print(f"ğŸ’¾ ÄÃ£ táº¡o má»›i file {CSV_FILE} vá»›i {len(df_new)} quÃ¡n.")
        return df_new

    # ğŸ§© Gá»™p dá»¯ liá»‡u cÅ© vÃ  má»›i
    try:
        df_old = pd.read_csv(CSV_FILE)
    except Exception:
        df_old = pd.DataFrame()

    df_all = pd.concat([df_old, df_new], ignore_index=True)
    df_all.drop_duplicates(subset=["ten_quan", "dia_chi"], inplace=True)
    df_all.to_csv(CSV_FILE, index=False)

    print(f"âœ… ÄÃ£ thÃªm {len(df_new)} quÃ¡n (sau khi lá»c trÃ¹ng: {len(df_all)}) vÃ o {CSV_FILE}")
    return df_new


# ğŸ‘‡ Crawl nhiá»u khu vá»±c (quáº­n) theo toáº¡ Ä‘á»™
if __name__ == "__main__":
    # Danh sÃ¡ch toáº¡ Ä‘á»™ trung tÃ¢m cÃ¡c quáº­n TP.HCM
    DISTRICTS = {
        #"Quáº­n 1": (10.7769, 106.7009),
        #"Quáº­n 3": (10.7840, 106.6945),
        "Quáº­n 5": (10.7520, 106.6620),
        #"BÃ¬nh Tháº¡nh": (10.8050, 106.6960),
        #"PhÃº Nhuáº­n": (10.7990, 106.6800),
        #"TÃ¢n BÃ¬nh": (10.8010, 106.6520),
        #"GÃ² Váº¥p": (10.8340, 106.6800),
        #"Quáº­n 10": (10.7735, 106.6670),
        #"Thá»§ Äá»©c": (10.8490, 106.7600)
    }

    query = input("ğŸ” Nháº­p tá»« khÃ³a muá»‘n tÃ¬m (vd: phá»Ÿ, trÃ  sá»¯a, cÆ¡m táº¥m): ").strip()
    print(f"ğŸš€ Báº¯t Ä‘áº§u crawl dá»¯ liá»‡u '{query}' cho {len(DISTRICTS)} khu vá»±c...\n")

    for district, (lat, lon) in DISTRICTS.items():
        print(f"ğŸ“ Äang crawl {query} táº¡i {district} ({lat}, {lon}) ...")
        data = get_places(query, lat, lon)
        save_places_to_csv(data, CSV_FILE)
        print(f"âœ… HoÃ n táº¥t {district}, tÃ¬m Ä‘Æ°á»£c {len(data)} Ä‘á»‹a Ä‘iá»ƒm.\n")
        time.sleep(5)  # nghá»‰ 5 giÃ¢y trÃ¡nh bá»‹ giá»›i háº¡n API

    print(f"ğŸ‰ HoÃ n táº¥t crawl táº¥t cáº£ khu vá»±c! Dá»¯ liá»‡u náº±m trong {CSV_FILE}")
